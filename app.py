import streamlit as st
#from main import update_faq, embed_query, query_top_k
import re
import json
import boto3
from pinecone import ServerlessSpec
from pinecone import Pinecone
import streamlit as st

pc = Pinecone(
    api_key="pcsk_2PqYLo_4z6FZVwzr9H3heXzps8m5MZcwsk6a5nvVveX6oh4axv8XSHXD1UY7Lq44v1k76o"
)

# Access AWS credentials from Streamlit secrets
aws_access_key_id = st.secrets.aws.aws_access_key_id
aws_secret_access_key = st.secrets.aws.aws_secret_access_key
region_name = st.secrets.aws.region_name

# Initialize a Boto3 session
session = boto3.Session(
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key,
    region_name=region_name
)

bedrock = boto3.client(service_name='bedrock-runtime', region_name = "us-east-1" )
modelId="amazon.titan-embed-text-v2:0"

index_name = "rubiesai"
index = pc.Index(index_name)

stats = index.describe_index_stats()
total_vectors = stats['total_vector_count']

new_id = total_vectors 


def update_faq(Question, Answer, id = new_id):
    """
    Chunking Strategy:
    1. Extract questions and answers from the text
    2. Ensure questions and answers are aligned
    3. Create chunks with questions and answers
    4. Return the chunks
    """

    # Prepare the input for the embedding model
    input_text = f"Q: {Question}\nA: {Answer}"

    # Create the input_data for the embedding request
    input_data = {
        "inputText": input_text,  # Embedding each chunk separately
        "dimensions": 1024,
        "normalize": True
    }

    # Serialize the data to JSON
    body = json.dumps(input_data).encode('utf-8')

    # Invoke Bedrock to get embeddings for this chunk
    response = bedrock.invoke_model(
        modelId=modelId,
        contentType="application/json",
        accept="*/*",
        body=body
    )

    response_body = response['body'].read()
    response_json = json.loads(response_body)

    # Extract the embedding for this chunk
    chunk_embedding = response_json['embedding']
    
    

    # Append the vector (ID, embedding, metadata)
    vectors = []
    vectors.append(
        (
            str(id),  # ID
            [chunk_embedding] if isinstance(chunk_embedding, float) else chunk_embedding,  # Vector
            {"question": Question, "answer": Answer}  # Metadata
        )
    )

    # Upsert vectors into the Pinecone index
    index.upsert(vectors=vectors)
    


def query_top_k(query_vector, top_k=5):
    """
    Queries the Pinecone index to retrieve the top_k most similar vectors.

    Args:
        query_vector (list): The query vector.
        top_k (int): Number of top similar vectors to retrieve.

    Returns:
        list: A list of tuples containing vector IDs and their corresponding metadata.
    """
    # Perform the query
    response = index.query(
        vector=query_vector,
        top_k=top_k,
        include_metadata=True
    )

    # Extract and return the results
    results = []
    for match in response['matches']:
        vector_id = match['id']
        metadata = match.get('metadata', {})
        question = metadata.get('question', 'N/A')
        answer = metadata.get('answer', 'N/A')
        results.append((vector_id, question, answer))
    
    return results

def embed_query(query):
    """
    Function to get the answer from the FAQ knowledge base using Pinecone, Embeddings, and Bedrock.
    
    Parameters:
    - query (str): The question the user asks.
    
    Returns:
    - str: The answer generated by the AI model based on the FAQ context.
    """
   # Create the input_data for the embedding request
    input_data = {
        "inputText": query,  # Embedding each chunk separately
        "dimensions": 1024,
        "normalize": True
    }

    # Send the query to Bedrock for embedding
    body = json.dumps(input_data).encode('utf-8')
    response = bedrock.invoke_model(
        modelId=modelId,
        contentType="application/json",
        accept="*/*",
        body=body
    )

    response_body = response['body'].read()
    response_json = json.loads(response_body)

    # Extract the query embedding from the response
    query_embedding = response_json['embedding']
    return query_embedding



st.title("RubiesAI FAQs Uploader")

def question_input():
    Question = st.text_input("Enter the Question here:")
    Answer = st.text_area("Enter the Answer here:")
    return Question, Answer

input = question_input()
if st.button('Submit FAQ'):
    if input:  # Ensure all inputs are filled
        final_output = update_faq(input[0], input[1])
        st.write("FAQs added successfully!")
    else:
        st.warning("Please fill out all fields before submitting.")



# Initialize session state for buttons
if 'show_update_form' not in st.session_state:
    st.session_state.show_update_form = False
if 'submit_updates' not in st.session_state:
    st.session_state.submit_updates = False
if 'faqs' not in st.session_state:
    st.session_state['faqs'] = []

# Function to display editable FAQs
def display_editable_faqs(faqs):
    edited_faqs = []
    for faq in faqs:
        st.write(f"**FAQ ID: {faq['id']}**")
        question = st.text_input(f"Edit Question (ID: {faq['id']})", value=faq['question'], key=f"question_{faq['id']}")
        answer = st.text_area(f"Edit Answer (ID: {faq['id']})", value=faq['answer'], key=f"answer_{faq['id']}")
        edited_faqs.append({"id": faq['id'], "question": question, "answer": answer})
        st.write("---")
    return edited_faqs


# Button to display editable FAQs
if st.button("Update FAQ"):
    st.session_state.show_update_form = True

# Display the query input and button if the form should be shown
if st.session_state.show_update_form:
    query = st.text_input("What Question are you trying to update?")
    if st.button("Query DB"):
        if query:
            query_vector = embed_query(query)
            if query_vector:
                faqs = query_top_k(query_vector, top_k=3)
                # Convert list of tuples to list of dictionaries
                st.session_state.faqs = [{'id': id_, 'question': question, 'answer': answer} for id_, question, answer in faqs]
            else:
                st.warning("Failed to generate query vector.")
        else:
            st.warning("Please enter a question to query.")

# Display the editable FAQs if they exist in session state
if st.session_state.faqs:
    for faq in st.session_state.faqs:
        st.text_input(f"Edit Question (ID: {faq['id']})", value=faq['question'], key=f"question_{faq['id']}")
        st.text_area(f"Edit Answer (ID: {faq['id']})", value=faq['answer'], key=f"answer_{faq['id']}")
        st.write("---")

    if st.button("Submit Updates"):
        # Process the updates
        updated_faqs = []
        for faq in st.session_state.faqs:
            updated_question = st.session_state.get(f"question_{faq['id']}", faq['question'])
            updated_answer = st.session_state.get(f"answer_{faq['id']}", faq['answer'])
            if updated_question != faq['question'] or updated_answer != faq['answer']:
                updated_faqs.append({
                    'id': faq['id'],
                    'question': updated_question,
                    'answer': updated_answer
                })
        if updated_faqs:
            st.write("The following FAQs have been updated:")
            for faq in updated_faqs:
                update_faq(faq['question'], faq['answer'], faq['id'])
                st.write(f"**ID:** {faq['id']}")
                st.write(f"**Question:** {faq['question']}")
                st.write(f"**Answer:** {faq['answer']}")
                st.write("---")
            # Here you can add the logic to update the database with the updated_faqs
        else:
            st.write("No changes detected.")
