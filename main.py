import re
import json
import boto3
from pinecone import ServerlessSpec
from pinecone import Pinecone
import streamlit as st

pc = Pinecone(
    api_key="pcsk_2PqYLo_4z6FZVwzr9H3heXzps8m5MZcwsk6a5nvVveX6oh4axv8XSHXD1UY7Lq44v1k76o"
)

# Access AWS credentials from Streamlit secrets
aws_access_key_id = st.secrets.aws.aws_access_key_id
aws_secret_access_key = st.secrets.aws.aws_secret_access_key
region_name = st.secrets.aws.region_name

# Initialize a Boto3 session
session = boto3.Session(
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key,
    region_name=region_name
)

bedrock = boto3.client(service_name='bedrock-runtime', region_name = "us-east-1" )
modelId="amazon.titan-embed-text-v2:0"

index_name = "rubiesai"
index = pc.Index(index_name)

stats = index.describe_index_stats()
total_vectors = stats['total_vector_count']

new_id = total_vectors 


def update_faq(Question, Answer, id = new_id):
    """
    Chunking Strategy:
    1. Extract questions and answers from the text
    2. Ensure questions and answers are aligned
    3. Create chunks with questions and answers
    4. Return the chunks
    """

    # Prepare the input for the embedding model
    input_text = f"Q: {Question}\nA: {Answer}"

    # Create the input_data for the embedding request
    input_data = {
        "inputText": input_text,  # Embedding each chunk separately
        "dimensions": 1024,
        "normalize": True
    }

    # Serialize the data to JSON
    body = json.dumps(input_data).encode('utf-8')

    # Invoke Bedrock to get embeddings for this chunk
    response = bedrock.invoke_model(
        modelId=modelId,
        contentType="application/json",
        accept="*/*",
        body=body
    )

    response_body = response['body'].read()
    response_json = json.loads(response_body)

    # Extract the embedding for this chunk
    chunk_embedding = response_json['embedding']
    
    

    # Append the vector (ID, embedding, metadata)
    vectors = []
    vectors.append(
        (
            str(id),  # ID
            [chunk_embedding] if isinstance(chunk_embedding, float) else chunk_embedding,  # Vector
            {"question": Question, "answer": Answer}  # Metadata
        )
    )

    # Upsert vectors into the Pinecone index
    index.upsert(vectors=vectors)
    


def query_top_k(query_vector, top_k=5):
    """
    Queries the Pinecone index to retrieve the top_k most similar vectors.

    Args:
        query_vector (list): The query vector.
        top_k (int): Number of top similar vectors to retrieve.

    Returns:
        list: A list of tuples containing vector IDs and their corresponding metadata.
    """
    # Perform the query
    response = index.query(
        vector=query_vector,
        top_k=top_k,
        include_metadata=True
    )

    # Extract and return the results
    results = []
    for match in response['matches']:
        vector_id = match['id']
        metadata = match.get('metadata', {})
        question = metadata.get('question', 'N/A')
        answer = metadata.get('answer', 'N/A')
        results.append((vector_id, question, answer))
    
    return results

def embed_query(query):
    """
    Function to get the answer from the FAQ knowledge base using Pinecone, Embeddings, and Bedrock.
    
    Parameters:
    - query (str): The question the user asks.
    
    Returns:
    - str: The answer generated by the AI model based on the FAQ context.
    """
   # Create the input_data for the embedding request
    input_data = {
        "inputText": query,  # Embedding each chunk separately
        "dimensions": 1024,
        "normalize": True
    }

    # Send the query to Bedrock for embedding
    body = json.dumps(input_data).encode('utf-8')
    response = bedrock.invoke_model(
        modelId=modelId,
        contentType="application/json",
        accept="*/*",
        body=body
    )

    response_body = response['body'].read()
    response_json = json.loads(response_body)

    # Extract the query embedding from the response
    query_embedding = response_json['embedding']
    return query_embedding

query  = "what are the kinds of accounts in Rubies Bank?"
query_vector = embed_query(query)
results = query_top_k(query_vector, top_k=5)
print(results)